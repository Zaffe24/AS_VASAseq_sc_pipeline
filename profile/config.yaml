  ##########################################
 #### snakemake & cluster paramaters ######
##########################################
# by Pietro Zafferani

snakefile: Snakefile
keep-going: False
latency-wait: 20
show-failed-logs: True
rerun-incomplete: True
reason: True
use-conda: True
max-jobs-per-second: 100

#### Times of re-running a failing rule####
restart-times: 0

#### set to True when testing the proper functioning of the pipeline ####
dry-run: False

#### set to True for adjourning the time-stamp of output files without having to regenerate them####
touch: False

#### Set to True to force Snakemake to re-run from scratch ####
forceall: False

#### Max number of jobs that can run simoultaneously on the cluster ####
jobs: 100

#### Value setting the maximum cap of total "points" that fast and slow running jobs can consume ####
resources:
  load=1000

#### command sent to the HPC cluster using SLURM syntax ####
cluster: "sbatch -p {resources.partition} -N {resources.node} -J \"{rule}.{wildcards}\" \
-e \"logs/{params.patient}/{rule}/{wildcards}_.err\"  -o \"logs/{params.patient}/{rule}/{wildcards}_.out\" -t {resources.runtime} --mem={resources.mem_mb}"

#### default cluster resources ####
default-resources:
  - partition=htc-el8
  - mem_mb=1000 # default is in MiB
  - node=1
  - runtime="4h"


##### set rule-specific cluster resources ####
set-resources:
##
  - trimming:mem_mb=300
##
  - ribo_depletion:mem_mb=3000
##
  - filtering_cleaned:mem_mb=2000
##
  - read_cleaning:mem_mb=40000 #35000
  - read_cleaning:partition=bigmem

  